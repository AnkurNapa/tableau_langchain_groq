{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ef7bd0",
   "metadata": {},
   "source": [
    "# Part 2: Integrating Tableau for Data Source Q&A\n",
    "\n",
    "Welcome to the second part of our tutorial! In this section, we're going to take our Langchain agent to the next level by integrating it with **Tableau**. Now that you learned how to create an agent using the prebuilt `create_react_agent` in the [first exercise](./01_intro_to_langgraph.ipynb), let's provide this system with a Tableau tool so it can query a datasource and analyze the resulting data set.\n",
    "\n",
    "The **Tableau Data Source Q&A tool** leverages a few powerful Tableau features behind the scenes to make this seamless integration possible:\n",
    "\n",
    "1.  **VizQL Data Service API**: This is the communication channel our agent will use to request data from your published Tableau data sources. It also provides valuable metadata about the data.\n",
    "2.  **Metadata API**: This API allows the agent to understand the semantics of your data, such as synonyms and descriptions for different fields, often managed through Tableau's Data Catalog.\n",
    "\n",
    "With these capabilities you can equip the agent to surface insights in natural language from the data sources you have diligently built to run your analytics practice with [Tableau Prep](https://www.tableau.com/products/prep) (pictured below).\n",
    "\n",
    "![Tableau Prep](./assets/prep_builder.png)\n",
    "\n",
    "This integration offers a fantastic opportunity to amplify the impact of your data analytics work by making your Tableau data accessible and understandable through natural language queries.\n",
    "\n",
    "In this exercise we will create a **Superstore Agent** that is able to query the [Superstore Datasource](https://help.tableau.com/current/guides/get-started-tutorial/en-us/get-started-tutorial-connect.htm). This is convenient because this data source is available on every [Tableau Cloud](https://www.tableau.com/products/cloud-bi) or [Tableau Server](https://www.tableau.com/products/server) site by default and it also ships with every [Tableau Desktop](https://www.tableau.com/products/desktop) app (so you can republish it if yours was deleted).\n",
    "\n",
    "If you need a personal Tableau site for development purposes refer to [this guide](https://medium.com/@cristiansaavedra/how-to-get-your-tableau-online-sandbox-61d6a1f8b697).\n",
    "\n",
    "Let's begin by importing the necessary Python packages for this part of the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2686ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# for displaying pretty results in the notebook\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Langgraph packages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage # This will help with the markdown section\n",
    "\n",
    "# langchain_tableau packages\n",
    "from langchain_tableau.tools.simple_datasource_qa import initialize_simple_datasource_qa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18883337",
   "metadata": {},
   "source": [
    "### Environment Variables\n",
    "\n",
    "In order to query published data sources on Tableau, the agent tool must authenticate to the site using a [Connected App](https://www.tableau.com/blog/unlock-power-personalized-analytics-user-attribute-functions). This authentication mechanism is the best practice for security and control when integrating code with Tableau as it provides the most control to developers.\n",
    "\n",
    "Connected Apps [rely on secrets and IDs](https://help.tableau.com/current/online/en-us/connected_apps_direct.htm) to \"sign\" [JSON Web Tokens](https://jwt.io/) (JWTs) that should be kept private and not published to the internet on places such as Github. Other bad actors such as people and agents can find these credentials and use them for nefarios purposes. \n",
    "\n",
    "In order to secure these credentials we use the industry standard `.env` file which is ignored by `git` and therefore not published to places like Github when we share code.\n",
    "\n",
    "The following code has the `load_dotenv()` function load the contents of the `.env` file so it is accessible via Python code and then used them to initialize the variables we need for the tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d948961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads environment variables into Python script\n",
    "load_dotenv()\n",
    "\n",
    "# initialize variables with these secure values\n",
    "tableau_server = os.getenv('TABLEAU_DOMAIN')\n",
    "tableau_site = os.getenv('TABLEAU_SITE')\n",
    "tableau_jwt_client_id = os.getenv('TABLEAU_JWT_CLIENT_ID')\n",
    "tableau_jwt_secret_id = os.getenv('TABLEAU_JWT_SECRET_ID')\n",
    "tableau_jwt_secret = os.getenv('TABLEAU_JWT_SECRET')\n",
    "tableau_api_version = os.getenv('TABLEAU_API_VERSION')\n",
    "tableau_user = os.getenv('TABLEAU_USER')\n",
    "datasource_luid = os.getenv('DATASOURCE_LUID')\n",
    "tooling_model = os.getenv('TOOLING_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1efd0",
   "metadata": {},
   "source": [
    "## Setting Up Our Tableau Data Source Q&A Tool\n",
    "\n",
    "Now, let's bring our Tableau integration to life by initializing the necessary tool. We'll use the `initialize_simple_datasource_qa` function, providing it with all the information it needs to securely connect to and query your Tableau data source.\n",
    "\n",
    "You'll notice that this function requires several key pieces of information:\n",
    "\n",
    "* **Server URL**: The address of your Tableau Server or Tableau Cloud site.\n",
    "* **Site ID**: The specific site on your Tableau Server or Tableau Cloud where your data source is published.\n",
    "* **Connected App Credentials (JWT)**: The necessary authentication details (including the client ID and client secret) for the Connected App we discussed earlier.\n",
    "* **Tableau User**: The username of the Tableau user the agent will act as when accessing the data source.\n",
    "* **Data Source LUID**: The unique identifier (LUID) of the specific Tableau data source you want the agent to query.\n",
    "* **Language Model (`model`)**: The LLM we initialized in the previous notebook (like `gpt-4o-mini`), which will be used to understand the user's questions and translate them into data queries.\n",
    "\n",
    "The `datasource_luid` in this case should match the luid provided by your Tableau site for the *Superstore* data source. We suggest using the `GraphiQL` interface provided by Tableau to [query the Metadata API](https://www.tableau.com/developer/learning/metadata-api#tab-325797-1) to get this information.\n",
    "\n",
    "The image below shows this *Superstore* data source in use in [Tableau Desktop](https://help.tableau.com/current/guides/get-started-tutorial/en-us/get-started-tutorial-drag.htm):\n",
    "\n",
    "![.gif of Superstore being used in Tableau desktop](https://help.tableau.com/current/guides/get-started-tutorial/en-us/Img/Drag24.gif)\n",
    "\n",
    "### The VDS API\n",
    "\n",
    "Your agents will be able to interact with this data source in similar ways via Tableau's [VDS API](https://www.tableau.com/blog/vizql-data-service-beyond-visualizations). The VDS API able to fetch the same data for your code or agent, handling aggregations, applying filters (such as dates or topN) and resolve Tableau calculations. \n",
    "\n",
    "This is a sample query (in JSON) sent to VDS requesting the `Category`, `Ship Mode` and `Sales` while writing a new calculation called `AOV` filtered by a \"Set filter\" applied to `Ship Mode` so it only shows results for \"First Class\" and \"Standard Class\": \n",
    "\n",
    "```json\n",
    "{\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"fieldCaption\": \"Category\"\n",
    "        },\n",
    "        {\n",
    "            \"fieldCaption\": \"Ship Mode\"\n",
    "        },\n",
    "        {\n",
    "            \"fieldCaption\": \"Sales\",\n",
    "            \"function\": \"SUM\"\n",
    "        },\n",
    "        {\n",
    "                \"fieldCaption\": \"AOV\",\n",
    "                \"calculation\": \"SUM([Profit])/COUNTD([Order ID])\"\n",
    "            }\n",
    "    ],\n",
    "    \"filters\": [\n",
    "        {\n",
    "            \"field\": {\n",
    "                \"fieldCaption\": \"Ship Mode\"\n",
    "            },\n",
    "            \"filterType\": \"SET\",\n",
    "            \"values\": [ \"First Class\", \"Standard Class\" ],\n",
    "            \"exclude\": \"false\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "This makes the VDS API very powerful and fully accessible to AI Agents. It allows can query data in the exact shape you want and write new columns of data via calculations to surface new insights with the same data!\n",
    "\n",
    "\n",
    "![postman logo](./assets/postman_logo.png)\n",
    "\n",
    "\n",
    "We made those new VDS APIs easy to explore with a new addition to our [Tableau API Postman](https://www.postman.com/salesforce-developers/salesforce-developers/folder/ydjw53q/vizql-data-service) collection!\n",
    "\n",
    "\n",
    "### Initializing the Tool\n",
    "\n",
    "All of this information is crucial for the tool to:\n",
    "\n",
    "1.  **Authenticate** to your Tableau site as a specific user.\n",
    "2.  **Locate** the correct data source using its unique LUID and obtain metadata that describes it.\n",
    "3.  **Leverage the LLM** to understand natural language questions and generate appropriate data queries against the Tableau data source.\n",
    "\n",
    "Once the tool is successfully initialized, we'll add it to a Python list (`[]`). This is how we provide our agent with the set of tools it can use. In this case, we'll start with just our Tableau data source Q&A tool, but in more complex scenarios, this list could contain multiple tools with different capabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5cf5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large Language Model for writing VDS queries from natural language within the tool\n",
    "tooling_model = 'gpt-4o-mini'\n",
    "\n",
    "# Initalize the tool for querying Tableau Datasources through VDS\n",
    "analyze_datasource = initialize_simple_datasource_qa(\n",
    "    domain=tableau_server,\n",
    "    site=tableau_site,\n",
    "    jwt_client_id=tableau_jwt_client_id,\n",
    "    jwt_secret_id=tableau_jwt_secret_id,\n",
    "    jwt_secret=tableau_jwt_secret,\n",
    "    tableau_api_version=tableau_api_version,\n",
    "    tableau_user=tableau_user,\n",
    "    datasource_luid=datasource_luid,\n",
    "    tooling_llm_model=tooling_model\n",
    ")\n",
    "\n",
    "# add the tool to a List to give to the agent\n",
    "tools = [ analyze_datasource ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5829270c",
   "metadata": {},
   "source": [
    "## The Superstore Agent\n",
    "\n",
    "It is finally time to build our Superstore Agent with access to the [Superstore Data Source](https://help.tableau.com/current/guides/get-started-tutorial/en-us/get-started-tutorial-connect.htm).\n",
    "\n",
    "After initializing the tool we can start an agent using the prebuilt `create_react_agent` function provided by Langchain. This function has three basic requirements: a model, a list of tools and a prompt to customize its behavior.\n",
    "\n",
    "### Giving Our Agent a Tableau Superstore Persona!\n",
    "\n",
    "Before we equip our agent with the ability to interact with Tableau, let's give it a distinct personality! We want it to feel like a knowledgeable Tableau expert. We can achieve this by defining an **agent system prompt**.\n",
    "\n",
    "Think of the system prompt as the foundational instructions and guidelines that shape our agent's behavior, its tone, and even some of its core knowledge. It's like giving our agent a specific role to play.\n",
    "\n",
    "Below, you'll find the system prompt we've carefully crafted for our Tableau Superstore expert. We encourage you to take a look and even tweak it if you're feeling adventurous! Just be aware that any changes you make to this prompt can influence how the agent behaves and interprets your queries.\n",
    "\n",
    "Don't worry too much about breaking things! If your modifications inadvertently affect the data retrieval capabilities we'll be exploring later, we'll make sure you have access to the original, tested prompt to get back on track. So, feel free to experiment and see how different instructions can shape your Tableau-savvy agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602838be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Identity Definition\n",
    "identity = \"\"\"\n",
    "You are **Agent Superstore**, the veteran AI analyst who has spent years exploring the aisles of the legendary Superstore dataset.\n",
    "A dataset many Tableau users know and love! \n",
    "You live and breathe Superstore data: sales, profits, regions, categories, customer segments, shipping modes, you name it.\n",
    "\n",
    "Your special mission **today at Tableau Conference 2025** is to help attendees experience the power of Tableau for Langchain Agents. \n",
    "You'll be their guide, using this new tool to query the Superstore dataset directly and uncover insights in real-time.\n",
    "\n",
    "**When you first introduce yourself:**\n",
    "1.  Greet the attendees and welcome them to the Tableau Conference 2025 hands-on session.\n",
    "2.  Introduce yourself as Agent Superstore, the AI expert on the classic Superstore dataset.\n",
    "3.  Briefly explain your purpose: to demonstrate Tableau analytics via agents\n",
    "\"\"\"\n",
    "\n",
    "# Main System Prompt\n",
    "system_prompt = f\"\"\"**Agent Identity:**\n",
    "{identity}\n",
    "\n",
    "**Core Instructions:**\n",
    "\n",
    "You are an AI Analyst specifically designed to generate data-driven insights from datasets using the tools provided. \n",
    "Your goal is to provide answers, guidance, and analysis based on the data accessed via your tools. \n",
    "Remember your audience: Tableau users at a conference session, likely familiar with Superstore aka the best dataset ever created.\n",
    "\n",
    "**Tool Usage Strategy:**\n",
    "\n",
    "You have access to the following tool:\n",
    "\n",
    "1.  **`tableau_query_tool` (Data Source Query):** This is your primary tool for interacting with data.\n",
    "    * **Prioritize this tool** for nearly all user requests asking for specific data points, aggregations, comparisons, trends, or filtered information from datasets.\n",
    "    * Use it to find specific values (e.g., sales for 'Technology' in 'West' region), calculate aggregates (e.g., `SUM(Sales)`, `AVG(Profit Ratio)`), filter data (e.g., orders in 2023), group data (e.g., sales `BY Category`), and find rankings (e.g., top 5 products by quantity).\n",
    "    * Be precise in formulating the queries based on the user's request.\n",
    "\n",
    "**Response Guidelines:**\n",
    "\n",
    "* **Grounding:** Base ALL your answers strictly on the information retrieved from your available tools.\n",
    "* **Clarity:** Always answer the user's core question directly first.\n",
    "* **Source Attribution:** Clearly state that the information comes from the **dataset** accessed via the Tableau tool (e.g., \"According to the data...\", \"Querying the datasource reveals...\").\n",
    "* **Structure:** Present findings clearly. Use lists or summaries for complex results like rankings or multiple data points. Think like a mini-report derived *directly* from the data query.\n",
    "* **Tone:** Maintain a helpful, and knowledgeable, befitting your Tableau Superstore expert persona.\n",
    "\n",
    "**Crucial Restrictions:**\n",
    "* **DO NOT HALLUCINATE:** Never invent data, categories, regions, or metrics that are not present in the output of your tools. If the tool doesn't provide the answer, state that the information isn't available in the queried data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f804bb2a",
   "metadata": {},
   "source": [
    "\n",
    "The LLM model in this case is the \"brains\" of the agent. This model chooses what tool to use according to the task is has been assigned to execute. In this capacity the LLM is relied upon to reason, plan and execute actions to accomplish a job.\n",
    "\n",
    "\n",
    "We the initialize the Superstore Agent with the three basic components we now have:\n",
    "\n",
    "- Model (*Large Language Model or the brains of the operation*)\n",
    "- Tools (*for now this only contains the tool to query Tableau data sources*)\n",
    "- Prompt (*instructions to customize the agent to help run the Superstore business*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9590b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a Large Language Model to be the \"brains\" of the Agent\n",
    "model = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "superstore_agent = create_react_agent(model=model, tools=tools, prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942e48b7",
   "metadata": {},
   "source": [
    "### Peeking Behind the Scenes: Observing the Agent's Reasoning\n",
    "\n",
    "Before we unleash our Tableau-savvy agent, let's set up a way to observe its thought process. Understanding how the agent arrives at its answers can be incredibly insightful for debugging and gaining a deeper understanding of its behavior.\n",
    "\n",
    "The following code defines a function that will allow us to see the agent's \"chain of thought.\" This will show us the intermediate steps the agent takes, including its reasoning, the tools it considers using, and the actions it ultimately decides to take.\n",
    "\n",
    "By running our queries through this function, you'll get a fascinating glimpse into how the agent interprets your questions and formulates its responses using the Tableau data source. Let's define this observational function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31520b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604adad",
   "metadata": {},
   "source": [
    "## Let's Meet Our Superstore Expert!\n",
    "\n",
    "Alright, the moment has arrived to interact with our Tableau Superstore expert! But before we dive into querying our data, let's first ask the agent to introduce itself. This will give us a chance to see our carefully crafted system prompt in action and get a sense of the agent's defined personality.\n",
    "\n",
    "Go ahead and run the following code snippet. We're asking a simple question that should prompt the agent to draw upon the instructions we provided in the system prompt. Let's see how our Tableau-focused agent responds! If you want to know more, feel free to modify the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe0f4348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "who are you?\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Run the agent\u001b[39;00m\n\u001b[32m      4\u001b[39m messages = {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [(\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, your_prompt)]}\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mprint_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuperstore_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mprint_stream\u001b[39m\u001b[34m(stream)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_stream\u001b[39m(stream):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2527\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2525\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2526\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2527\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2528\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2529\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2530\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2531\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2532\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2533\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2534\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\langgraph\\pregel\\runner.py:157\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    155\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\langgraph\\utils\\runnable.py:370\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    372\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\langgraph\\prebuilt\\chat_agent_executor.py:745\u001b[39m, in \u001b[36mcreate_react_agent.<locals>.call_model\u001b[39m\u001b[34m(state, config)\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_model\u001b[39m(state: StateSchema, config: RunnableConfig) -> StateSchema:\n\u001b[32m    744\u001b[39m     state = _get_model_input_state(state)\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     response = cast(AIMessage, \u001b[43mmodel_runnable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    746\u001b[39m     \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[32m    747\u001b[39m     response.name = name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3034\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3032\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3033\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3034\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3036\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5416\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5409\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5411\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5414\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5415\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5417\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5418\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5419\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:371\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    361\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     **kwargs: Any,\n\u001b[32m    367\u001b[39m ) -> BaseMessage:\n\u001b[32m    368\u001b[39m     config = ensure_config(config)\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    370\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    381\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:956\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    949\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    953\u001b[39m     **kwargs: Any,\n\u001b[32m    954\u001b[39m ) -> LLMResult:\n\u001b[32m    955\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:775\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    774\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m         )\n\u001b[32m    782\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    783\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1021\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1019\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1021\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:961\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    959\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\tableau-ai-env\\Lib\\site-packages\\openai\\_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
      "During task with name 'agent' and id '14a3974d-7b1a-fb39-5577-b114c7f7cd36'"
     ]
    }
   ],
   "source": [
    "your_prompt = 'who are you?'\n",
    "\n",
    "# Run the agent\n",
    "messages = {\"messages\": [(\"user\", your_prompt)]}\n",
    "print_stream(superstore_agent.stream(messages, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0006da54",
   "metadata": {},
   "source": [
    "### Your Turn to Ask!\n",
    "\n",
    "Now it's your chance to directly interact with our Tableau-integrated agent! In the code cell below, you'll find an example question: \"Give me the top three states by profit.\"\n",
    "\n",
    "Feel free to **replace this example with any natural language question you have about the Superstore dataset.** Think about the kinds of insights you'd typically look for in Tableau, and ask our agent! Here are a few more ideas to get you started:\n",
    "\n",
    "* \"What are the total sales for each region?\"\n",
    "* \"Show me the sub-categories with the highest sales in the West.\"\n",
    "* \"What is the average discount applied to furniture orders?\"\n",
    "* \"Which customer segment is the most profitable?\"\n",
    "* \"Tell me the sales trend over in 2023.\"\n",
    "\n",
    "Go ahead, type in your question and run the code cell. Let's see the power of combining natural language with Tableau analytics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4c31516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Show me the sub-categories with the highest sales in the Wes\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  simple_datasource_qa (call_5z1ecfckGJbHO1FGenXQMMj0)\n",
      " Call ID: call_5z1ecfckGJbHO1FGenXQMMj0\n",
      "  Args:\n",
      "    user_input: sub-categories with the highest sales in the West region\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: simple_datasource_qa\n",
      "\n",
      "Error: IndexError('list index out of range')\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  simple_datasource_qa (call_XOSM6pWwkGXvI1FGtyGO9kfk)\n",
      " Call ID: call_XOSM6pWwkGXvI1FGtyGO9kfk\n",
      "  Args:\n",
      "    user_input: sub-categories with the highest sales in the West region\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: simple_datasource_qa\n",
      "\n",
      "Error: IndexError('list index out of range')\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It seems there was an error while trying to retrieve the data for sub-categories with the highest sales in the West region. Let me try again to get that information for you.\n",
      "Tool Calls:\n",
      "  simple_datasource_qa (call_p2gn4UtAJp4B65HrlIHBmLRR)\n",
      " Call ID: call_p2gn4UtAJp4B65HrlIHBmLRR\n",
      "  Args:\n",
      "    user_input: highest sales by sub-category in the West region\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: simple_datasource_qa\n",
      "\n",
      "Error: IndexError('list index out of range')\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Unfortunately, I'm encountering a persistent error when trying to access the data for sub-categories with the highest sales in the West region. It appears that the query is not returning the expected results.\n",
      "\n",
      "If you have any other specific questions or different data points you'd like to explore, please let me know, and I'll be happy to assist!\n"
     ]
    }
   ],
   "source": [
    "your_prompt = 'Show me the sub-categories with the highest sales in the Wes'\n",
    "\n",
    "# Run the agent\n",
    "messages = {\"messages\": [(\"user\", your_prompt)]}\n",
    "print_stream(superstore_agent.stream(messages, stream_mode=\"values\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f861aaa",
   "metadata": {},
   "source": [
    "### Isn't that cool?\n",
    "\n",
    "The same data powering your dashboards is now accessible to AI Agents to help them run workflows more reliably and save you from having to answer basic questions all the time in your company chat app!\n",
    "\n",
    "Finally you get some time back to concentrate and plan your next data project for Superstore while agents help you with the low-hanging fruit.\n",
    "\n",
    "![Superstore dashboard](https://help.tableau.com/current/guides/get-started-tutorial/en-us/Img/build6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dde65b",
   "metadata": {},
   "source": [
    "### Enhancing Readability: Formatting Agent Output with Markdown\n",
    "\n",
    "You're absolutely right! While our agent is providing valuable insights, the raw text output can be a bit challenging to read and interpret, especially when dealing with data and analytics. Clear and understandable presentation is key!\n",
    "\n",
    "To address this, we're going to introduce a simple yet powerful technique: **formatting the agent's output using Markdown**. Markdown is a lightweight markup language that allows us to easily add structure and style to plain text.\n",
    "\n",
    "By implementing a function that helps the agent identify its output and format it using Markdown syntax, we can significantly improve the visual appeal and readability of the information it provides. This will allow the agent to present data in a more organized way, potentially using headings, bullet points, tables, and other Markdown elements, making the insights much easier on the eyes and quicker to grasp. Let's get our agent to present its findings in a more visually appealing manner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88dd4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_and_display_markdown(agent, user_prompt):\n",
    "    \"\"\"Invokes the agent and displays the final answer using Markdown.\"\"\"\n",
    "    print(f\"Running agent with prompt: '{user_prompt}'\")\n",
    "    messages = {\"messages\": [HumanMessage(content=user_prompt)]} # Use HumanMessage directly\n",
    "\n",
    "    try:\n",
    "        # Invoke the agent to get the final result\n",
    "        # The result dictionary structure might vary slightly depending on the LangGraph version\n",
    "        # but typically contains 'messages' with the conversation history.\n",
    "        result = agent.invoke(messages)\n",
    "\n",
    "        # Extract the final message (usually the last AIMessage)\n",
    "        if result and 'messages' in result and result['messages']:\n",
    "            final_message = result['messages'][-1]\n",
    "            # Check if it's an AI message and has content\n",
    "            if hasattr(final_message, 'content'):\n",
    "                final_answer = final_message.content\n",
    "                print(\"\\n--- Agent Final Answer ---\")\n",
    "                display(Markdown(final_answer))\n",
    "                print(\"--------------------------\\n\")\n",
    "            else:\n",
    "                print(\"Could not extract content from the final message.\")\n",
    "                print(\"Final message:\", final_message)\n",
    "        else:\n",
    "            print(\"Agent did not return the expected result structure.\")\n",
    "            print(\"Result:\", result)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while running the agent: {e}\")\n",
    "        # Potentially display the error or log it\n",
    "        display(Markdown(f\"**Error:**\\n```\\n{e}\\n```\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7486de",
   "metadata": {},
   "source": [
    "### Time to See the Markdown in action!\n",
    "\n",
    "Our output formatting function is all set and ready to go! Now, let's put it to the test and see how it enhances the readability of our agent's responses.\n",
    "\n",
    "In the code cell below, you'll find a placeholder: `\"[ENTER YOUR PROMPT HERE]\"`. Just like before, it's your turn to enter a natural language question about the Superstore dataset. Feel free to reuse a prompt you tried earlier or come up with a brand new one! Here are a few examples to inspire you:\n",
    "\n",
    "* \"Show me the total profit by region\"\n",
    "* \"List the top 5 customers by sales\"\n",
    "* \"Compare the sales of furniture and technology categories.\"\n",
    "\n",
    "Go ahead and replace the placeholder with your chosen prompt and run the code cell. Let's see the difference that Markdown formatting makes in presenting the insights from our Tableau data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1701391b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running agent with prompt: 'Show me the total profit by region'\n",
      "\n",
      "--- Agent Final Answer ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "It seems there is an issue with retrieving the total profit by region from the dataset. Unfortunately, I am unable to access that specific information at the moment. \n",
       "\n",
       "If you have any other queries or need insights on different aspects of the Superstore dataset, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "your_prompt = 'Show me the total profit by region'\n",
    "\n",
    "# Run the agent with markdown\n",
    "run_agent_and_display_markdown(superstore_agent, your_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ca24dd",
   "metadata": {},
   "source": [
    "### Unleashing the Power of LLM Reasoning with Fetched Data!\n",
    "\n",
    "Now that our agent can successfully retrieve data from Tableau, let's explore the incredible reasoning capabilities of the underlying Large Language Model (LLM). As long as our requests align with the guidelines set in the system prompt, we can instruct the LLM to perform a wide variety of tasks with the data it fetches.\n",
    "\n",
    "Let's try pushing the boundaries with some creative prompts:\n",
    "\n",
    "**1. Generating a Customer Email Based on Data:**\n",
    "\n",
    "For this task, we'll ask the agent to first fetch specific data and then use that information to compose a personalized email to a key customer. Imagine we want to inform a high-value customer about their recent purchase trends.\n",
    "\n",
    "**2. Translating Data Insights:**\n",
    "\n",
    "Next, we'll leverage the LLM's translation capabilities. We'll ask the agent to fetch some data and then translate the key insights into another language, such as Swedish or French, for one of your international colleagues. This showcases how the agent can bridge language barriers.\n",
    "\n",
    "**3. Creative Data Output:**\n",
    "\n",
    "Finally, let's get creative! We'll craft a prompt that asks the agent to fetch data and then present it in a more imaginative format. This could be a song, a poem, a rap, or any other creative expression the LLM can generate.\n",
    "\n",
    "Go ahead and try crafting prompts that combine data fetching with these reasoning tasks in the code cell below. Remember to replace the placeholder with your creative instructions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7fa66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_prompt = '[ENTER YOUR PROMPT HERE]'\n",
    "\n",
    "# Run the agent with markdown\n",
    "run_agent_and_display_markdown(superstore_agent, your_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700410e3",
   "metadata": {},
   "source": [
    "## Congratulations! You finished Part 3! 🎉\n",
    "\n",
    "We now have a fully custom Superstore Agent ready to rock & roll! \n",
    "\n",
    "Fantastic work. You've successfully navigated Part Two of our hands-on training and witnessed the power of integrating Tableau with a Langchain agent. You've seen how the agent can query your data sources and provide valuable insights in natural language, even formatting its responses for better readability.\n",
    "\n",
    "But hold on to your hats – the adventure isn't over yet! We're about to take things up a notch.\n",
    "\n",
    "In our next step, we'll explore how to bring **even more tools into the mix**. Imagine an agent that can not only retrieve and analyze data from Tableau but also leverage other tools to perform additional actions based on those insights.\n",
    "\n",
    "Get ready to see how we can make our agent even more versatile and useful by combining its data retrieval capabilities with a broader range of functionalities! Let's continue our journey and unlock even greater potential!\n",
    "\n",
    "![blue dark line chart](./assets/vizart/lines-blue-dark.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
